# instruction-attack
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models
